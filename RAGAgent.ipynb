{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11ecacd-7425-4103-a36e-3f477a389ad9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workers.py\n",
    "import torch\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import ThreadedPdfPipelineOptions, RapidOcrOptions, PdfBackend\n",
    "from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions\n",
    "\n",
    "def gpu_worker(paper_chunk, gpu_id):\n",
    "    device_str = f\"cuda:{gpu_id}\"\n",
    "    \n",
    "    acc_options = AcceleratorOptions(device=device_str, num_threads=4)\n",
    "    pipe_options = ThreadedPdfPipelineOptions(\n",
    "        accelerator_options=acc_options,\n",
    "        ocr_batch_size=32,      \n",
    "        pdf_backend=PdfBackend.PYPDFIUM2,\n",
    "        do_ocr=True,\n",
    "        ocr_options=RapidOcrOptions(backend=\"torch\")\n",
    "    )\n",
    "    \n",
    "    converter = DocumentConverter(format_options={\"pdf\": PdfFormatOption(pipeline_options=pipe_options)})\n",
    "    \n",
    "    # NEW: We store results as a list of objects instead of one big string\n",
    "    processed_papers = []\n",
    "    \n",
    "    for paper in paper_chunk:\n",
    "        try:\n",
    "            print(f\"GPU {gpu_id} reading: {paper['title'][:50]}...\")\n",
    "            result = converter.convert(paper['link'])\n",
    "            content = result.document.export_to_markdown()\n",
    "            \n",
    "            # Package the content with its citation metadata\n",
    "            processed_papers.append({\n",
    "                \"title\": paper['title'],\n",
    "                \"link\": paper['link'],\n",
    "                \"source\": paper.get('source', 'Unknown'),\n",
    "                \"text\": content\n",
    "            })\n",
    "            torch.cuda.empty_cache() \n",
    "        except Exception as e:\n",
    "            print(f\"GPU {gpu_id} error on {paper['title'][:20]}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return processed_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "862a3f81-45e1-46c1-9297-a6b123643caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Tells Python to stay quiet about \"FutureWarnings\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import arxiv\n",
    "import requests\n",
    "import multiprocessing as mp\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from workers import gpu_worker \n",
    "\n",
    "# --- CONFIGS ---\n",
    "PROJECT_ID = \"dulcet-asset-208017\" \n",
    "SS_API_KEY = \"VA0cJSDyrN9ExLvIPBns74HhMxuCPYuy6v11bJzS\"\n",
    "LOCATION = \"us-central1\"\n",
    "TOP_K_READ = 10 \n",
    "\n",
    "# Initialize Google Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# --- SEARCH ENGINE ---\n",
    "def unified_scourer(query, ss_key, max_results=40):\n",
    "    all_results = []\n",
    "    seen_titles = set()\n",
    "    print(f\"üîç Scouring ArXiv & Semantic Scholar for: {query}...\")\n",
    "    \n",
    "    # ArXiv\n",
    "    client = arxiv.Client()\n",
    "    for r in client.results(arxiv.Search(query=query, max_results=max_results)):\n",
    "        t_norm = \"\".join(filter(str.isalnum, r.title.lower()))\n",
    "        all_results.append({\"title\": r.title, \"link\": r.pdf_url, \"abstract\": r.summary})\n",
    "        seen_titles.add(t_norm)\n",
    "\n",
    "    # Semantic Scholar\n",
    "    ss_url = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={query}&limit={max_results}&fields=title,openAccessPdf,abstract\"\n",
    "    try:\n",
    "        res = requests.get(ss_url, headers={\"x-api-key\": ss_key}).json()\n",
    "        for p in res.get('data', []):\n",
    "            t_norm = \"\".join(filter(str.isalnum, p['title'].lower()))\n",
    "            pdf = (p.get('openAccessPdf') or {}).get('url')\n",
    "            if t_norm not in seen_titles and pdf:\n",
    "                all_results.append({\"title\": p['title'], \"link\": pdf, \"abstract\": p.get('abstract', '')})\n",
    "    except: pass\n",
    "    return all_results\n",
    "\n",
    "# --- VERTEX AI JUDGE ---\n",
    "def judge_papers(candidates, topic):\n",
    "    \"\"\"Uses Gemini 2.5 Flash-Lite (the 2026 standard) for fast filtering.\"\"\"\n",
    "    print(f\"‚öñÔ∏è Judging {len(candidates)} candidates via Vertex AI (Gemini 2.5)...\")\n",
    "    \n",
    "    judge_model = GenerativeModel(\"gemini-2.5-flash-lite\")\n",
    "    winners = []\n",
    "    \n",
    "    for paper in candidates[:20]:\n",
    "        prompt = (f\"Topic: {topic}\\nPaper: {paper['title']}\\n\"\n",
    "                  f\"Abstract: {paper['abstract'][:500]}\\n\"\n",
    "                  \"Is this paper highly relevant? Reply ONLY 'YES' or 'NO'.\")\n",
    "        try:\n",
    "            resp = judge_model.generate_content(prompt)\n",
    "            if \"YES\" in resp.text.upper():\n",
    "                winners.append(paper)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Judging error: {e}\")\n",
    "            continue\n",
    "        if len(winners) >= TOP_K_READ: break\n",
    "    return winners\n",
    "    \n",
    "# --- THE MISSION CONTROL ---\n",
    "def run_research_mission(topic_name):\n",
    "    start_total = time.time()\n",
    "    \n",
    "    # 1. Triage\n",
    "    candidates = unified_scourer(topic_name, SS_API_KEY)\n",
    "    winners = judge_papers(candidates, topic_name)\n",
    "    \n",
    "    if not winners:\n",
    "        print(f\"No relevant papers found.\")\n",
    "        return None\n",
    "\n",
    "    # 2. Parallel Shredder (Local T4 GPUs)\n",
    "    mid = len(winners) // 2\n",
    "    chunks = [winners[:mid], winners[mid:]]\n",
    "    print(f\"üöÄ Deploying 2x T4 GPUs to shred {len(winners)} papers...\")\n",
    "    \n",
    "    ctx = mp.get_context('spawn')\n",
    "    with ctx.Pool(processes=2) as pool:\n",
    "        worker_outputs = pool.starmap(gpu_worker, [(chunks[0], 0), (chunks[1], 1)])\n",
    "    \n",
    "    all_docs = [doc for sublist in worker_outputs for doc in sublist]\n",
    "    \n",
    "    # 3. Citation & Corpus Map\n",
    "    full_corpus = \"\"\n",
    "    bibliography = \"\\n\\n# References\\n\"\n",
    "    for i, doc in enumerate(all_docs):\n",
    "        ref_num = i + 1\n",
    "        full_corpus += f\"\\n--- DATA FROM SOURCE [{ref_num}] ---\\n{doc['text']}\\n\"\n",
    "        bibliography += f\"[{ref_num}] {doc['title']}. Link: {doc['link']}\\n\"\n",
    "    \n",
    "    # 4. Vertex AI Synthesis (Llama 3.3 70B with Literature Matrix)\n",
    "    print(f\"Synthesizing Narrative & Literature Matrix via Llama 3.3 70B...\")\n",
    "\n",
    "    LLAMA_PATH = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/meta/models/llama-3.3-70b-instruct-maas\"\n",
    "    writer_model = GenerativeModel(LLAMA_PATH)\n",
    "    \n",
    "    system_instr = (\n",
    "        f\"You are a Senior Silicon Architect. Analyze the data into a 2000-word deep-dive on {topic_name}.\\n\"\n",
    "        \"Use in-text citations like [1] or [2] for every technical fact based ONLY on 'DATA FROM SOURCE [X]' headers.\\n\\n\"\n",
    "        \"### REQUIRED ADD-ON: LITERATURE SYNTHESIS MATRIX\\n\"\n",
    "        \"At the very end of your report, provide a structured Markdown table summarizing the current work found in the sources. \"\n",
    "        \"Use these columns:\\n\"\n",
    "        \"| Source [Ref] | Research Objective | Hardware/Methodology | Work Done / Key Findings |\\n\"\n",
    "        \"| :--- | :--- | :--- | :--- |\\n\"\n",
    "        \"Ensure the 'Work Done' column specifically addresses the query topic.\"\n",
    "    )\n",
    "    \n",
    "    final_prompt = f\"{system_instr}\\n\\nHardware Raw Data (Source Material):\\n{full_corpus[:38000]}\"\n",
    "    \n",
    "    try:\n",
    "        report = writer_model.generate_content(final_prompt).text\n",
    "    except Exception as e:\n",
    "        print(f\"Synthesis Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 5. Save & Finish\n",
    "    final_output = report + bibliography\n",
    "    filename = f\"{topic_name.replace(' ', '_')}_Synthesis_Matrix.md\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(final_output)\n",
    "    \n",
    "    print(f\"\\n‚úÖ MISSION COMPLETE. Time: {round((time.time()-start_total)/60, 2)}m. Saved to {filename}\")\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802e97d6-61d6-41de-9bbd-ce39ce7549d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 18:42:44,704 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=NVIDIA+Hopper&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scouring ArXiv & Semantic Scholar for: NVIDIA Hopper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 18:42:45,499 - INFO - Got first page: 100 of 3117 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Judging 43 candidates via Vertex AI (Gemini 2.5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Deploying 2x T4 GPUs to shred 7 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 18:42:59,085 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:42:59,099 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:42:59,099 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e4c42daca97a8e21534d8c76e00da367\n",
      "2026-01-09 18:42:59,110 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:42:59,112 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 18:42:59,121 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:42:59,123 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:42:59,125 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 18:42:59,139 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:42:59,139 - INFO - Initializing pipeline for StandardPdfPipeline with options hash bcaac49b74d25edc113eed3b5c5ed5f6\n",
      "2026-01-09 18:42:59,151 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:42:59,152 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 18:42:59,164 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:42:59,166 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 18:42:59,967 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 18:42:59,976 - INFO - Accelerator device: 'cuda:1'\n",
      "\u001b[32m[INFO] 2026-01-09 18:42:59,998 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,002 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,009 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,012 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,041 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,042 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,051 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,052 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,987 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,987 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,990 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:00,990 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,006 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,007 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,009 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,009 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,096 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,097 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,117 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,117 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,168 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,169 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,188 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 18:43:01,188 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 18:43:01,520 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:43:01,523 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 18:43:01,528 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 18:43:01,549 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:43:01,552 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 18:43:01,557 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 18:43:02,361 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:43:02,362 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 18:43:02,431 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 18:43:02,598 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 18:43:02,599 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 18:43:02,670 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 18:43:03,016 - INFO - Processing document 2402.13499v1.pdf\n",
      "2026-01-09 18:43:03,294 - INFO - Processing document 2312.11918v1.pdf\n",
      "2026-01-09 18:43:10,280 - INFO - Finished converting document 2312.11918v1.pdf in 11.29 sec.\n",
      "2026-01-09 18:43:10,476 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:43:10,481 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:43:10,481 - INFO - Processing document 2404.13195v5.pdf\n",
      "2026-01-09 18:43:13,211 - INFO - Finished converting document 2404.13195v5.pdf in 2.83 sec.\n",
      "2026-01-09 18:43:15,852 - INFO - Finished converting document 2402.13499v1.pdf in 16.90 sec.\n",
      "2026-01-09 18:43:16,146 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:43:16,157 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:43:16,157 - INFO - Processing document 2501.12084v2.pdf\n",
      "2026-01-09 18:43:17,869 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:43:17,903 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:43:17,903 - INFO - Processing document 2208.05581v1.pdf\n",
      "2026-01-09 18:43:25,814 - INFO - Finished converting document 2208.05581v1.pdf in 12.57 sec.\n",
      "2026-01-09 18:43:25,981 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:43:25,989 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:43:25,989 - INFO - Processing document 2507.02770v1.pdf\n",
      "2026-01-09 18:43:30,407 - INFO - Finished converting document 2501.12084v2.pdf in 14.46 sec.\n",
      "2026-01-09 18:43:30,969 - INFO - Finished converting document 2507.02770v1.pdf in 5.09 sec.\n",
      "2026-01-09 18:43:31,450 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 18:43:31,458 - INFO - Going to convert document batch...\n",
      "2026-01-09 18:43:31,458 - INFO - Processing document 2409.03992v4.pdf\n",
      "2026-01-09 18:43:38,774 - INFO - Finished converting document 2409.03992v4.pdf in 8.24 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 1 reading: A Case Study in CUDA Kernel Fusion: Implementing F...\n",
      "GPU 1 reading: Automatic BLAS Offloading on Unified Memory Archit...\n",
      "GPU 1 reading: Hopper flows of deformable particles...\n",
      "GPU 1 reading: NVIDIA GPU Confidential Computing Demystified...\n",
      "Synthesizing Narrative & Literature Matrix via Llama 3.3 70B...\n",
      "\n",
      "‚úÖ MISSION COMPLETE. Time: 1.01m. Saved to NVIDIA_Hopper_Synthesis_Matrix.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a Senior Silicon Architect, I will provide a deep-dive analysis of NVIDIA Hopper, a cutting-edge GPU architecture designed to accelerate artificial intelligence (AI) and high-performance computing (HPC) workloads.\\n\\n**Introduction**\\n\\nNVIDIA Hopper is the latest GPU architecture from NVIDIA, designed to provide significant performance and power efficiency improvements over its predecessors, Ampere and Ada Lovelace [1]. Hopper introduces several innovative features, including new tensor cores, dynamic programming X (DPX) instructions, distributed shared memory, and an enhanced asynchronous execution mechanism.\\n\\n**Tensor Cores**\\n\\nTensor cores are a critical component of modern GPU architectures, responsible for accelerating deep learning and AI workloads [2]. Hopper introduces new tensor cores that support FP8, DPX, and distributed shared memory. The tensor cores are designed to provide higher performance and efficiency for AI workloads, with support for mixed-precision computing and sparse matrix multiplication.\\n\\n**DPX Instructions**\\n\\nDPX instructions are a new feature in Hopper, designed to accelerate dynamic programming algorithms [3]. DPX instructions provide a significant performance boost for workloads that rely heavily on dynamic programming, such as natural language processing and computer vision.\\n\\n**Distributed Shared Memory**\\n\\nDistributed shared memory is a new feature in Hopper that enables direct SM-to-SM communication, allowing threads from one thread block to access shared memory of another block [4]. This feature provides significant performance improvements for workloads that rely heavily on shared memory access.\\n\\n**Asynchronous Execution**\\n\\nHopper introduces an enhanced asynchronous execution mechanism, which allows for non-blocking data transfers between GPU global memory and shared memory [5]. This feature provides significant performance improvements for workloads that rely heavily on data transfers.\\n\\n**Performance Analysis**\\n\\nOur performance analysis shows that Hopper provides significant performance improvements over its predecessors, Ampere and Ada Lovelace [6]. The new tensor cores, DPX instructions, and distributed shared memory features provide a significant boost to AI and HPC workloads.\\n\\n**Memory Latencies and Throughputs**\\n\\nOur analysis shows that Hopper provides similar memory access latencies to its predecessors, with an average latency of 40.7 clock cycles for L1 cache access [7]. However, Hopper provides higher memory throughputs, with a maximum throughput of 1861.5 GB/s for global memory access.\\n\\n**Tensor Core Latencies and Throughputs**\\n\\nOur analysis shows that Hopper's tensor cores provide higher throughputs and lower latencies than its predecessors [8]. The new tensor cores support FP8, DPX, and distributed shared memory, providing a significant boost to AI workloads.\\n\\n**Conclusion**\\n\\nIn conclusion, NVIDIA Hopper is a significant improvement over its predecessors, providing higher performance, power efficiency, and innovative features such as DPX instructions and distributed shared memory. Our analysis shows that Hopper provides significant performance improvements for AI and HPC workloads, making it an attractive option for datacenter and cloud computing applications.\\n\\n**Literature Synthesis Matrix**\\n\\n| Source [Ref] | Research Objective | Hardware/Methodology | Work Done / Key Findings |\\n| --- | --- | --- | --- |\\n| [1] | Analyze Hopper GPU architecture | Hopper GPU, CUDA 12.1 | Introduced new tensor cores, DPX instructions, and distributed shared memory |\\n| [2] | Evaluate tensor core performance | Hopper GPU, PTX-level microbenchmarks | Higher throughputs and lower latencies for tensor core operations |\\n| [3] | Investigate DPX instruction performance | Hopper GPU, CUDA 12.1 | Significant performance boost for dynamic programming algorithms |\\n| [4] | Analyze distributed shared memory performance | Hopper GPU, CUDA 12.1 | Significant performance improvements for workloads that rely heavily on shared memory access |\\n| [5] | Evaluate asynchronous execution performance | Hopper GPU, CUDA 12.1 | Significant performance improvements for workloads that rely heavily on data transfers |\\n| [6] | Compare Hopper performance with predecessors | Hopper GPU, Ampere GPU, Ada Lovelace GPU | Significant performance improvements for AI and HPC workloads |\\n| [7] | Measure memory latencies and throughputs | Hopper GPU, CUDA 12.1 | Similar memory access latencies, higher memory throughputs |\\n| [8] | Evaluate tensor core latencies and throughputs | Hopper GPU, PTX-level microbenchmarks | Higher throughputs and lower latencies for tensor core operations |\\n\\nNote: The references in the literature synthesis matrix are based on the provided source material and may not be actual references.\\n\\n# References\\n[1] Benchmarking and Dissecting the Nvidia Hopper GPU Architecture. Link: https://arxiv.org/pdf/2402.13499v1\\n[2] Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and Multiple Level Analysis. Link: https://arxiv.org/pdf/2501.12084v2\\n[3] Confidential Computing on NVIDIA Hopper GPUs: A Performance Benchmark Study. Link: https://arxiv.org/pdf/2409.03992v4\\n[4] A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library. Link: https://arxiv.org/pdf/2312.11918v1\\n[5] Automatic BLAS Offloading on Unified Memory Architecture: A Study on NVIDIA Grace-Hopper. Link: https://arxiv.org/pdf/2404.13195v5\\n[6] Hopper flows of deformable particles. Link: https://arxiv.org/pdf/2208.05581v1\\n[7] NVIDIA GPU Confidential Computing Demystified. Link: https://arxiv.org/pdf/2507.02770v1\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a high-end hardware comparison\n",
    "run_research_mission(\"NVIDIA Hopper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562ba4ca-050d-49ca-b8ba-dd6bb384f825",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 15:59:28,902 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=NVIDIA+Blackwell+NVLink+Speeds&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scouring ArXiv & Semantic Scholar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 15:59:30,035 - INFO - Got first page: 100 of 71759 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging 43 candidates for architectural density...\n",
      "Deploying 2x T4 GPUs for 20 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 15:59:39,982 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 15:59:39,996 - INFO - Going to convert document batch...\n",
      "2026-01-09 15:59:39,997 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e4c42daca97a8e21534d8c76e00da367\n",
      "2026-01-09 15:59:40,008 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:40,009 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 15:59:40,020 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:40,022 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 15:59:40,907 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:40,938 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:40,940 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:40,980 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:40,980 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,551 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,551 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,554 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,554 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,669 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,669 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,742 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:41,742 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 15:59:42,070 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:42,073 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 15:59:42,078 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 15:59:42,783 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:42,783 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 15:59:42,850 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 15:59:43,396 - INFO - Processing document 2403.08719v2.pdf\n",
      "2026-01-09 15:59:43,824 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 15:59:43,876 - INFO - Going to convert document batch...\n",
      "2026-01-09 15:59:43,876 - INFO - Initializing pipeline for StandardPdfPipeline with options hash bcaac49b74d25edc113eed3b5c5ed5f6\n",
      "2026-01-09 15:59:43,889 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:43,890 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 15:59:43,905 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:43,908 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 15:59:44,509 - INFO - Accelerator device: 'cuda:1'\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:44,545 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:44,549 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:44,594 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:44,595 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,221 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,221 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,224 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,224 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,338 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,339 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,412 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 15:59:45,412 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 15:59:45,837 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:45,839 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 15:59:45,845 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 15:59:46,838 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 15:59:46,839 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 15:59:46,903 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 15:59:47,459 - INFO - Processing document 2310.17062v3.pdf\n",
      "2026-01-09 15:59:54,279 - INFO - Finished converting document 2403.08719v2.pdf in 14.67 sec.\n",
      "2026-01-09 15:59:54,765 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 15:59:54,768 - INFO - Going to convert document batch...\n",
      "2026-01-09 15:59:54,769 - INFO - Processing document 2303.04956v2.pdf\n",
      "2026-01-09 15:59:54,945 - INFO - Finished converting document 2310.17062v3.pdf in 15.41 sec.\n",
      "2026-01-09 15:59:56,619 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 15:59:56,628 - INFO - Going to convert document batch...\n",
      "2026-01-09 15:59:56,628 - INFO - Processing document 1602.08124v3.pdf\n",
      "2026-01-09 16:00:00,935 - INFO - Finished converting document 1602.08124v3.pdf in 5.91 sec.\n",
      "2026-01-09 16:00:01,130 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:01,144 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:01,145 - INFO - Processing document 2312.03618v3.pdf\n",
      "2026-01-09 16:00:02,600 - INFO - Finished converting document 2303.04956v2.pdf in 8.20 sec.\n",
      "2026-01-09 16:00:03,039 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:03,041 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:03,042 - INFO - Processing document 1003.2489v1.pdf\n",
      "2026-01-09 16:00:04,812 - INFO - Finished converting document 1003.2489v1.pdf in 2.13 sec.\n",
      "2026-01-09 16:00:05,202 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:05,206 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:05,207 - INFO - Processing document 1011.1936v1.pdf\n",
      "2026-01-09 16:00:10,113 - INFO - Finished converting document 1011.1936v1.pdf in 5.26 sec.\n",
      "2026-01-09 16:00:16,124 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:16,128 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:16,128 - INFO - Processing document paper0704.pdf\n",
      "2026-01-09 16:00:20,097 - INFO - Finished converting document paper0704.pdf in 9.92 sec.\n",
      "2026-01-09 16:00:20,355 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:20,356 - INFO - Finished converting document 2312.03618v3.pdf in 19.35 sec.\n",
      "2026-01-09 16:00:20,374 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:20,374 - INFO - Processing document 2507.10789v2.pdf\n",
      "2026-01-09 16:00:20,850 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:20,868 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:20,869 - INFO - Processing document 2103.15196v1.pdf\n",
      "2026-01-09 16:00:27,981 - INFO - Finished converting document 2103.15196v1.pdf in 7.45 sec.\n",
      "2026-01-09 16:00:30,525 - INFO - Finished converting document 2507.10789v2.pdf in 10.37 sec.\n",
      "2026-01-09 16:00:30,726 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:30,728 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:30,729 - INFO - Processing document 1102.2729v1.pdf\n",
      "2026-01-09 16:00:34,968 - INFO - Finished converting document 1102.2729v1.pdf in 4.35 sec.\n",
      "2026-01-09 16:00:35,130 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:35,133 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:35,133 - INFO - Processing document 2012.14043v1.pdf\n",
      "2026-01-09 16:00:36,042 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:36,152 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:36,153 - INFO - Processing document 2508.16401v1.pdf\n",
      "2026-01-09 16:00:38,336 - INFO - Finished converting document 2012.14043v1.pdf in 3.32 sec.\n",
      "2026-01-09 16:00:38,503 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:38,506 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:38,507 - INFO - Processing document 2201.05148v1.pdf\n",
      "2026-01-09 16:00:39,790 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:00:41,272 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:00:50,393 - INFO - Finished converting document 2201.05148v1.pdf in 12.01 sec.\n",
      "2026-01-09 16:00:50,782 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:00:50,790 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:00:50,790 - INFO - Processing document 2404.13195v5.pdf\n",
      "2026-01-09 16:00:55,748 - INFO - Finished converting document 2404.13195v5.pdf in 5.18 sec.\n",
      "2026-01-09 16:01:02,190 - INFO - Finished converting document 2508.16401v1.pdf in 34.11 sec.\n",
      "2026-01-09 16:01:02,557 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:01:02,562 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:01:02,563 - INFO - Processing document 1808.04871v3.pdf\n",
      "2026-01-09 16:01:15,808 - INFO - Finished converting document 1808.04871v3.pdf in 13.39 sec.\n",
      "2026-01-09 16:01:16,024 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:01:16,027 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:01:16,028 - INFO - Processing document 0703121v2.pdf\n",
      "2026-01-09 16:01:19,211 - INFO - Finished converting document 0703121v2.pdf in 3.31 sec.\n",
      "2026-01-09 16:01:19,759 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:01:19,817 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:01:19,818 - INFO - Processing document 2503.14492v2.pdf\n",
      "2026-01-09 16:01:32,022 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:01:38,107 - INFO - Finished converting document 2503.14492v2.pdf in 18.84 sec.\n",
      "2026-01-09 16:01:38,983 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:01:38,999 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:01:39,000 - INFO - Processing document 2302.00036v1.pdf\n",
      "2026-01-09 16:01:45,366 - INFO - Finished converting document 2302.00036v1.pdf in 7.17 sec.\n",
      "2026-01-09 16:01:47,162 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:01:47,181 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:01:47,182 - INFO - Processing document 1903.04611v1.pdf\n",
      "2026-01-09 16:01:55,329 - INFO - Finished converting document 1903.04611v1.pdf in 9.89 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• GPU 1 active on: An Open, Programmable, Multi-vendor 5G O...\n",
      "üî• GPU 1 active on: vDNN: Virtualized Deep Neural Networks f...\n",
      "üî• GPU 1 active on: Beyond discounted returns: Robust Markov...\n",
      "üî• GPU 1 active on: Application of Graphics Processing Units...\n",
      "üî• GPU 1 active on: Audio2Face-3D: Audio-driven Realistic Fa...\n",
      "üî• GPU 1 active on: Rao-Blackwellizing Field Goal Percentage...\n",
      "üî• GPU 1 active on: Causality and the speed of sound...\n",
      "üî• GPU 1 active on: Cosmos-Transfer1: Conditional World Gene...\n",
      "üî• GPU 1 active on: Reducing Blackwell and Average Optimalit...\n",
      "üî• GPU 1 active on: Evaluating Modern GPU Interconnect: PCIe...\n",
      "Synthesizing Meta-Report on NVIDIA Blackwell NVLink Speeds via Llama 3.3 70B...\n",
      "\n",
      "MISSION COMPLETE. Total Time: 2.5 minutes.\n",
      "Report saved to NVIDIA_Blackwell_NVLink_Speeds_Report.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to provide a deep-dive analysis of NVIDIA Blackwell NVLink speeds. However, I must point out that the provided text appears to be unrelated to the topic of NVIDIA Blackwell NVLink speeds. The text seems to be discussing Homomorphic Secret Sharing (HSS) schemes, which is a cryptography-related topic.\\n\\nAssuming that you'd like me to provide a general analysis of NVIDIA Blackwell NVLink speeds, I'll provide an overview of the topic.\\n\\n**Introduction**\\n\\nNVIDIA's NVLink is a high-speed interconnect technology designed to provide low-latency and high-bandwidth communication between NVIDIA graphics processing units (GPUs) and other components such as central processing units (CPUs) and memory. The Blackwell architecture is a specific implementation of NVLink, which is used in NVIDIA's datacenter-focused products, such as the NVIDIA A100 GPU.\\n\\n**Interconnects**\\n\\nNVLink is a serial, point-to-point interconnect that uses a differential signaling scheme to transmit data over copper or optical cables. The Blackwell architecture uses a 19.2 Gbps signaling rate, which provides a maximum bandwidth of 100 GB/s per link. Each NVLink port can support up to 6 links, resulting in a maximum bandwidth of 600 GB/s per port.\\n\\n**Chiplet Layout**\\n\\nThe Blackwell architecture uses a chiplet-based design, where the GPU is divided into smaller, modular components called chiplets. Each chiplet contains a specific function, such as graphics processing, tensor processing, or memory control. The chiplets are connected using NVLink, which allows for high-bandwidth and low-latency communication between the different components.\\n\\n**Memory Throughput**\\n\\nThe Blackwell architecture is designed to provide high memory throughput, which is essential for applications such as artificial intelligence, deep learning, and high-performance computing. The architecture uses a combination of NVLink and traditional memory interfaces, such as DDR4 or HBM2, to provide a maximum memory bandwidth of over 1.5 TB/s.\\n\\n**NVLink Speeds**\\n\\nThe NVLink speeds in the Blackwell architecture are as follows:\\n\\n* NVLink 1: 20 Gbps per lane, 80 Gbps per port (4 lanes)\\n* NVLink 2: 25 Gbps per lane, 100 Gbps per port (4 lanes)\\n* NVLink 3: 19.2 Gbps per lane, 100 GB/s per port (6 lanes)\\n\\nThe Blackwell architecture uses NVLink 3, which provides a maximum bandwidth of 600 GB/s per port.\\n\\n**Conclusion**\\n\\nIn conclusion, the NVIDIA Blackwell NVLink speeds are designed to provide high-bandwidth and low-latency communication between GPUs and other components. The Blackwell architecture uses a chiplet-based design and a combination of NVLink and traditional memory interfaces to provide high memory throughput. The NVLink speeds in the Blackwell architecture are up to 100 GB/s per port, with a maximum bandwidth of 600 GB/s per port.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_research_mission(\"NVIDIA Blackwell NVLink Speeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2cfc18-2033-4e8b-a2ba-47c8e290e80b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:03:26,135 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=NVIDIA+H100&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scouring ArXiv & Semantic Scholar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:03:27,303 - INFO - Got first page: 100 of 2929 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging 49 candidates for architectural density...\n",
      "Deploying 2x T4 GPUs for 20 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:03:37,503 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:03:37,545 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:03:37,546 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e4c42daca97a8e21534d8c76e00da367\n",
      "2026-01-09 16:03:37,549 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:03:37,558 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:37,559 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:03:37,572 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:37,572 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:03:37,572 - INFO - Initializing pipeline for StandardPdfPipeline with options hash bcaac49b74d25edc113eed3b5c5ed5f6\n",
      "2026-01-09 16:03:37,574 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:03:37,584 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:37,585 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:03:37,598 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:37,600 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:03:38,430 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:03:38,433 - INFO - Accelerator device: 'cuda:1'\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,464 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,464 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,468 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,468 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,509 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,509 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,512 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:38,513 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,521 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,522 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,524 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,524 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,524 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,524 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,527 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,527 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,633 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,633 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,647 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,647 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,706 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,706 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,728 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:03:39,728 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 16:03:40,078 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:40,082 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:03:40,088 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:03:40,106 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:40,108 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:03:40,114 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:03:40,962 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:40,962 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:03:41,033 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:03:41,172 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:03:41,172 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:03:41,237 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:03:41,600 - INFO - Processing document 2510.00392v1.pdf\n",
      "2026-01-09 16:03:41,799 - INFO - Processing document 2503.11901v4.pdf\n",
      "2026-01-09 16:03:49,225 - INFO - Finished converting document 2503.11901v4.pdf in 11.87 sec.\n",
      "2026-01-09 16:03:49,493 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:03:49,544 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:03:49,545 - INFO - Processing document 2511.00088v2.pdf\n",
      "2026-01-09 16:03:52,563 - INFO - Finished converting document 2510.00392v1.pdf in 15.21 sec.\n",
      "2026-01-09 16:03:52,831 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:03:52,862 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:03:52,862 - INFO - Processing document 2310.17062v3.pdf\n",
      "2026-01-09 16:04:00,523 - INFO - Finished converting document 2310.17062v3.pdf in 7.86 sec.\n",
      "2026-01-09 16:04:00,713 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:04:00,718 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:04:00,718 - INFO - Processing document 1807.07382v3.pdf\n",
      "2026-01-09 16:04:11,188 - INFO - Finished converting document 1807.07382v3.pdf in 10.62 sec.\n",
      "2026-01-09 16:04:12,089 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:04:12,101 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:04:12,101 - INFO - Processing document 2110.00459v1.pdf\n",
      "2026-01-09 16:04:15,060 - INFO - Finished converting document 2511.00088v2.pdf in 25.73 sec.\n",
      "2026-01-09 16:04:18,033 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:04:18,055 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:04:18,056 - INFO - Processing document 2303.13545v1.pdf\n",
      "2026-01-09 16:04:21,638 - INFO - Finished converting document 2110.00459v1.pdf in 10.39 sec.\n",
      "2026-01-09 16:04:23,009 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:04:23,065 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:04:23,065 - INFO - Processing document 2312.02741v3.pdf\n",
      "2026-01-09 16:05:01,503 - INFO - Finished converting document 2312.02741v3.pdf in 39.79 sec.\n",
      "2026-01-09 16:05:01,838 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:01,851 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:01,852 - INFO - Processing document 2508.14444v4.pdf\n",
      "2026-01-09 16:05:16,067 - INFO - Finished converting document 2508.14444v4.pdf in 14.48 sec.\n",
      "2026-01-09 16:05:16,384 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:16,438 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:16,439 - INFO - Processing document 2312.02741v3.pdf\n",
      "2026-01-09 16:05:17,463 - INFO - Finished converting document 2303.13545v1.pdf in 62.25 sec.\n",
      "2026-01-09 16:05:17,763 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:17,766 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:17,766 - INFO - Processing document 2307.09782v2.pdf\n",
      "2026-01-09 16:05:24,286 - INFO - Finished converting document 2307.09782v2.pdf in 6.63 sec.\n",
      "2026-01-09 16:05:24,591 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:24,693 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:24,694 - INFO - Processing document 2508.16401v1.pdf\n",
      "2026-01-09 16:05:27,855 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:05:28,732 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:05:42,443 - INFO - Finished converting document 2508.16401v1.pdf in 18.06 sec.\n",
      "2026-01-09 16:05:42,793 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:42,803 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:42,804 - INFO - Processing document 2507.10789v2.pdf\n",
      "2026-01-09 16:05:52,293 - INFO - Finished converting document 2507.10789v2.pdf in 9.72 sec.\n",
      "2026-01-09 16:05:54,780 - INFO - Finished converting document 2312.02741v3.pdf in 38.61 sec.\n",
      "2026-01-09 16:05:54,993 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:55,001 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:55,002 - INFO - Processing document 2507.02770v1.pdf\n",
      "2026-01-09 16:05:59,513 - INFO - Finished converting document 2507.02770v1.pdf in 4.65 sec.\n",
      "2026-01-09 16:05:59,783 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:05:59,789 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:05:59,789 - INFO - Processing document 2305.10553v1.pdf\n",
      "2026-01-09 16:06:03,783 - INFO - Finished converting document 2305.10553v1.pdf in 4.19 sec.\n",
      "2026-01-09 16:06:04,355 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2026-01-09 16:06:04,390 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:06:04,390 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2026-01-09 16:06:04,391 - INFO - Processing document access.2025.3554728\n",
      "2026-01-09 16:06:04,404 - INFO - Finished converting document access.2025.3554728 in 0.58 sec.\n",
      "2026-01-09 16:06:06,483 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:06:06,656 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:06:06,657 - INFO - Processing document 2507.16781v1.pdf\n",
      "\u001b[33m[WARNING] 2026-01-09 16:06:15,220 [RapidOCR] main.py:125: The text detection result is empty\u001b[0m\n",
      "2026-01-09 16:06:15,221 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:06:16,242 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:06:16,412 - WARNING - RapidOCR returned empty result!\n",
      "\u001b[33m[WARNING] 2026-01-09 16:06:16,507 [RapidOCR] main.py:125: The text detection result is empty\u001b[0m\n",
      "2026-01-09 16:06:16,507 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:06:16,634 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:06:18,205 - INFO - Finished converting document 2507.16781v1.pdf in 25.82 sec.\n",
      "2026-01-09 16:06:18,954 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:06:18,961 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:06:18,961 - INFO - Processing document 2104.07735v1.pdf\n",
      "2026-01-09 16:06:30,166 - INFO - Finished converting document 2104.07735v1.pdf in 11.86 sec.\n",
      "2026-01-09 16:06:31,077 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:06:31,109 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:06:31,109 - INFO - Processing document 2503.14492v2.pdf\n",
      "2026-01-09 16:06:37,987 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:06:45,336 - INFO - Finished converting document 2503.14492v2.pdf in 14.42 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing Meta-Report on NVIDIA H100 via Llama 3.3 70B...\n",
      "\n",
      "MISSION COMPLETE. Total Time: 3.4 minutes.\n",
      "Report saved to NVIDIA_H100_Report.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Introduction to NVIDIA H100**\\n\\nThe NVIDIA H100 is a cutting-edge GPU accelerator designed to deliver unprecedented AI compute throughput, optimized transformer acceleration, and energy efficiency improvements. Built on the Hopper architecture, the H100 GPU provides a significant boost in performance and power efficiency compared to its predecessors. In this analysis, we will delve into the interconnects, chiplet layout, and memory throughput of the NVIDIA H100, with a focus on its applications in deep learning and artificial intelligence.\\n\\n**Interconnects: NVLink and PCI Express**\\n\\nThe NVIDIA H100 features a high-speed interconnect called NVLink, which provides a bandwidth of up to 900 GB/s. NVLink is a proprietary interconnect technology developed by NVIDIA, designed to enable high-speed communication between GPUs, CPUs, and other components. The H100 also supports PCI Express (PCIe) 4.0, which offers a maximum bandwidth of 32 GB/s per lane. The combination of NVLink and PCIe 4.0 enables the H100 to communicate efficiently with other components in a system, reducing latency and increasing overall system performance.\\n\\n**Chiplet Layout: MCM and 3D Stacking**\\n\\nThe NVIDIA H100 employs a multi-chip module (MCM) design, which involves integrating multiple smaller chips (or chiplets) into a single package. This approach allows for increased density, improved yields, and reduced manufacturing costs. The H100's MCM design features a combination of logic, memory, and interface chiplets, all connected using advanced packaging technologies such as 3D stacking and silicon interposers. The 3D stacking technology enables the H100 to stack multiple layers of memory and logic, increasing the overall memory bandwidth and reducing latency.\\n\\n**Memory Throughput: HBM3 and GDDR6**\\n\\nThe NVIDIA H100 supports two types of memory: High-Bandwidth Memory 3 (HBM3) and Graphics Double Data Rate 6 (GDDR6). HBM3 is a high-density, low-power memory technology that offers a bandwidth of up to 3.2 GB/s per pin. The H100 features up to 80 GB of HBM3 memory, providing a total bandwidth of 3.2 TB/s. In addition to HBM3, the H100 also supports GDDR6 memory, which offers a bandwidth of up to 16 GB/s per pin. The combination of HBM3 and GDDR6 enables the H100 to deliver high memory bandwidth and capacity, making it suitable for demanding applications such as deep learning, scientific simulations, and data analytics.\\n\\n**Transformer Engine and Tensor Cores**\\n\\nThe NVIDIA H100 features a dedicated Transformer Engine, which is designed to accelerate transformer-based workloads such as natural language processing (NLP) and computer vision. The Transformer Engine is optimized for matrix multiplication, attention mechanisms, and other critical components of transformer architectures. The H100 also features fourth-generation Tensor Cores, which provide a significant boost in performance and power efficiency compared to previous generations. The Tensor Cores are designed to accelerate matrix multiplication, convolution, and other critical operations in deep learning workloads.\\n\\n**Applications: Deep Learning and AI**\\n\\nThe NVIDIA H100 is designed to accelerate a wide range of deep learning and AI workloads, including computer vision, NLP, and recommender systems. The H100's high memory bandwidth, large memory capacity, and advanced tensor core architecture make it an ideal platform for training large-scale deep learning models. The H100 also supports a wide range of frameworks and libraries, including TensorFlow, PyTorch, and NVIDIA's own cuDNN and TensorRT. With its unprecedented performance and power efficiency, the H100 is poised to revolutionize the field of AI and deep learning, enabling applications such as autonomous vehicles, medical imaging, and natural language processing.\\n\\n**Conclusion**\\n\\nIn conclusion, the NVIDIA H100 is a powerful GPU accelerator that delivers unprecedented AI compute throughput, optimized transformer acceleration, and energy efficiency improvements. The H100's interconnects, chiplet layout, and memory throughput make it an ideal platform for deep learning and AI workloads. With its advanced tensor core architecture, dedicated Transformer Engine, and high-speed memory, the H100 is poised to revolutionize the field of AI and deep learning, enabling applications that were previously unimaginable. As the demand for AI and deep learning continues to grow, the NVIDIA H100 is set to play a critical role in shaping the future of computing.\\n\\n**Appendix: Technical Specifications**\\n\\n* **GPU Architecture:** Hopper\\n* **CUDA Cores:** 14592\\n* **Tensor Cores:** 4th generation\\n* **Memory:** Up to 80 GB HBM3, up to 32 GB GDDR6\\n* **Memory Bandwidth:** Up to 3.2 TB/s (HBM3), up to 512 GB/s (GDDR6)\\n* **NVLink:** Up to 900 GB/s\\n* **PCIe:** PCIe 4.0\\n* **Power Consumption:** Up to 700W\\n* **Form Factor:** Full-height, full-length\\n* **Cooling:** Active cooling (air or liquid)\\n\\nNote: The technical specifications listed above are subject to change and may not reflect the final production specifications.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_research_mission(\"NVIDIA H100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5412ba92-cac4-43d0-9457-2287fce75db2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:07:48,691 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=NVIDIA+5090&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scouring ArXiv & Semantic Scholar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:07:50,064 - INFO - Got first page: 100 of 2874 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging 56 candidates for architectural density...\n",
      "Deploying 2x T4 GPUs for 20 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:08:00,464 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:00,509 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:00,509 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e4c42daca97a8e21534d8c76e00da367\n",
      "2026-01-09 16:08:00,510 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:00,521 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:00,522 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:08:00,530 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:00,530 - INFO - Initializing pipeline for StandardPdfPipeline with options hash bcaac49b74d25edc113eed3b5c5ed5f6\n",
      "2026-01-09 16:08:00,533 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:00,536 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:08:00,541 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:00,542 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:08:00,553 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:00,555 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:08:01,368 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:08:01,370 - INFO - Accelerator device: 'cuda:1'\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,401 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,401 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,404 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,404 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,443 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,443 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,445 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:01,446 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,483 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,483 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,486 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,486 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,489 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,490 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,492 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,492 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,599 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,599 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,608 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,609 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,671 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,671 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,689 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:08:02,689 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 16:08:03,018 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:03,021 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:08:03,027 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:08:03,052 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:03,055 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:08:03,061 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:08:03,823 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:03,824 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:08:03,892 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:08:04,033 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:08:04,034 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:08:04,108 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:08:04,497 - INFO - Processing document 2503.14492v2.pdf\n",
      "2026-01-09 16:08:04,718 - INFO - Processing document 2511.03929v2.pdf\n",
      "2026-01-09 16:08:12,372 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:08:17,692 - INFO - Finished converting document 2503.14492v2.pdf in 17.50 sec.\n",
      "2026-01-09 16:08:17,917 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:17,920 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:17,921 - INFO - Processing document 1803.04014v1.pdf\n",
      "2026-01-09 16:08:22,414 - INFO - Finished converting document 1803.04014v1.pdf in 4.62 sec.\n",
      "2026-01-09 16:08:22,492 - INFO - Finished converting document 2511.03929v2.pdf in 22.15 sec.\n",
      "2026-01-09 16:08:22,599 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:22,603 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:22,604 - INFO - Processing document 2502.15773v1.pdf\n",
      "2026-01-09 16:08:22,775 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:22,780 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:22,781 - INFO - Processing document 1804.06826v1.pdf\n",
      "2026-01-09 16:08:24,347 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:08:26,018 - INFO - Finished converting document 2502.15773v1.pdf in 3.55 sec.\n",
      "2026-01-09 16:08:26,458 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:26,462 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:26,463 - INFO - Processing document 1304.7053v1.pdf\n",
      "2026-01-09 16:08:32,852 - INFO - Finished converting document 1304.7053v1.pdf in 6.80 sec.\n",
      "2026-01-09 16:08:33,965 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:33,979 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:33,979 - INFO - Processing document 2508.14444v4.pdf\n",
      "2026-01-09 16:08:46,910 - INFO - Finished converting document 2508.14444v4.pdf in 13.07 sec.\n",
      "2026-01-09 16:08:47,166 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:08:47,216 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:08:47,217 - INFO - Processing document 2511.00088v2.pdf\n",
      "2026-01-09 16:09:10,499 - INFO - Finished converting document 2511.00088v2.pdf in 23.49 sec.\n",
      "2026-01-09 16:09:10,827 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:10,875 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:10,876 - INFO - Processing document 2312.02741v3.pdf\n",
      "2026-01-09 16:09:18,371 - INFO - Finished converting document 1804.06826v1.pdf in 55.73 sec.\n",
      "2026-01-09 16:09:19,135 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:19,141 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:19,142 - INFO - Processing document 1808.07984v1.pdf\n",
      "2026-01-09 16:09:29,943 - INFO - Finished converting document 1808.07984v1.pdf in 11.36 sec.\n",
      "2026-01-09 16:09:31,283 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:31,287 - ERROR - An unexpected error occurred while opening the document CiSE2022-elster-haugdahl-NTNU-copy-MCSE3163817_2.pdf\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/docling/datamodel/document.py\", line 177, in __init__\n",
      "    self._init_doc(backend, path_or_stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/docling/datamodel/document.py\", line 221, in _init_doc\n",
      "    self._backend = backend(self, path_or_stream=path_or_stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/docling/backend/docling_parse_v4_backend.py\", line 205, in __init__\n",
      "    self._pdoc = pdfium.PdfDocument(self.path_or_stream, password=password)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 78, in __init__\n",
      "    self.raw, to_hold, to_close = _open_pdf(self._input, self._password, self._autoclose)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pypdfium2/_helpers/document.py\", line 678, in _open_pdf\n",
      "    raise PdfiumError(f\"Failed to load document (PDFium: {pdfium_i.ErrorToStr.get(err_code)}).\")\n",
      "pypdfium2._helpers.misc.PdfiumError: Failed to load document (PDFium: Data format error).\n",
      "2026-01-09 16:09:31,290 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:31,492 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:31,599 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:31,600 - INFO - Processing document 2508.16401v1.pdf\n",
      "2026-01-09 16:09:34,920 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:09:35,737 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:09:49,086 - INFO - Finished converting document 2312.02741v3.pdf in 38.46 sec.\n",
      "2026-01-09 16:09:49,359 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:49,362 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:49,362 - INFO - Processing document 2009.02449v4.pdf\n",
      "2026-01-09 16:09:51,033 - INFO - Finished converting document 2508.16401v1.pdf in 19.74 sec.\n",
      "2026-01-09 16:09:51,273 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:09:51,280 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:09:51,280 - INFO - Processing document 2512.20856v1.pdf\n",
      "2026-01-09 16:09:56,008 - INFO - Finished converting document 2009.02449v4.pdf in 6.84 sec.\n",
      "2026-01-09 16:09:57,983 - INFO - Finished converting document 2512.20856v1.pdf in 6.81 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• GPU 0 active on: Cosmos-Transfer1: Conditional World Gene...\n",
      "üî• GPU 0 active on: NVIDIA Tensor Core Programmability, Perf...\n",
      "üî• GPU 0 active on: JExplore: Design Space Exploration Tool ...\n",
      "üî• GPU 0 active on: A GEMM interface and implementation on N...\n",
      "üî• GPU 0 active on: A Modular AI-Driven Intrusion Detection ...\n",
      "‚ö†Ô∏è GPU 0 error on A Modular AI-Driven : 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/25/1/130\n",
      "üî• GPU 0 active on: NVIDIA at the Center of the Generative A...\n",
      "‚ö†Ô∏è GPU 0 error on NVIDIA at the Center: 403 Client Error: Forbidden for url: https://dl.acm.org/doi/pdf/10.1145/3631537\n",
      "üî• GPU 0 active on: NVIDIA Nemotron Nano 2: An Accurate and ...\n",
      "üî• GPU 0 active on: Alpamayo-R1: Bridging Reasoning and Acti...\n",
      "üî• GPU 0 active on: Part-time Power Measurements: nvidia-smi...\n",
      "üî• GPU 0 active on: Hierarchical Roofline Analysis: How to C...\n",
      "Synthesizing Meta-Report on NVIDIA 5090 via Llama 3.3 70B...\n",
      "\n",
      "MISSION COMPLETE. Total Time: 2.26 minutes.\n",
      "Report saved to NVIDIA_5090_Report.md\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_research_mission(\"NVIDIA 5090\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4531f33-89f0-4314-8933-9ddaeef59d05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:14:32,829 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Intel+Arc+B-Series&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scouring ArXiv & Semantic Scholar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:14:33,925 - INFO - Got first page: 100 of 15855 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging 52 candidates for architectural density...\n",
      "Deploying 2x T4 GPUs for 20 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 16:14:44,287 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:44,300 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:44,300 - INFO - Initializing pipeline for StandardPdfPipeline with options hash bcaac49b74d25edc113eed3b5c5ed5f6\n",
      "2026-01-09 16:14:44,311 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:44,313 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:14:44,325 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:44,327 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:14:44,340 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:44,352 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:44,352 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e4c42daca97a8e21534d8c76e00da367\n",
      "2026-01-09 16:14:44,364 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:44,366 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-09 16:14:44,377 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:44,379 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-09 16:14:45,172 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:14:45,176 - INFO - Accelerator device: 'cuda:1'\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,204 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,207 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,208 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,211 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,247 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,247 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,250 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:45,250 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,485 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,485 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,485 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,485 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,487 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,487 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,488 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,488 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,639 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,639 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,639 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,639 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,711 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,711 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,711 [RapidOCR] download_file.py:60: File exists and is valid: /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-09 16:14:46,711 [RapidOCR] main.py:50: Using /opt/conda/lib/python3.10/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2026-01-09 16:14:47,193 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:47,194 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:47,196 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:14:47,196 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-09 16:14:47,201 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:14:47,202 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:14:48,030 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:48,031 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:14:48,110 - INFO - Accelerator device: 'cuda:0'\n",
      "2026-01-09 16:14:48,200 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-09 16:14:48,201 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-09 16:14:48,266 - INFO - Accelerator device: 'cuda:1'\n",
      "2026-01-09 16:14:48,684 - INFO - Processing document 2411.11206v1.pdf\n",
      "2026-01-09 16:14:48,846 - INFO - Processing document 0902.3039v1.pdf\n",
      "2026-01-09 16:14:51,859 - INFO - Finished converting document 0902.3039v1.pdf in 7.65 sec.\n",
      "2026-01-09 16:14:52,212 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:52,213 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:52,214 - INFO - Processing document 1412.4022v2.pdf\n",
      "2026-01-09 16:14:53,459 - INFO - Finished converting document 2411.11206v1.pdf in 9.24 sec.\n",
      "2026-01-09 16:14:53,641 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:53,643 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:53,643 - INFO - Processing document 0902.3298v1.pdf\n",
      "2026-01-09 16:14:54,203 - INFO - Finished converting document 1412.4022v2.pdf in 2.28 sec.\n",
      "2026-01-09 16:14:54,629 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:54,632 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:54,632 - INFO - Processing document 1705.04706v3.pdf\n",
      "2026-01-09 16:14:55,171 - INFO - Finished converting document 0902.3298v1.pdf in 1.62 sec.\n",
      "2026-01-09 16:14:55,355 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:14:55,358 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:14:55,358 - INFO - Processing document 0303052v4.pdf\n",
      "2026-01-09 16:15:01,194 - INFO - Finished converting document 1705.04706v3.pdf in 6.96 sec.\n",
      "2026-01-09 16:15:01,390 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:01,394 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:01,395 - INFO - Processing document 1103.3732v1.pdf\n",
      "2026-01-09 16:15:10,040 - INFO - Finished converting document 0303052v4.pdf in 14.84 sec.\n",
      "2026-01-09 16:15:10,878 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:10,886 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:10,887 - INFO - Processing document 2103.10116v1.pdf\n",
      "2026-01-09 16:15:12,982 - INFO - Finished converting document 1103.3732v1.pdf in 11.73 sec.\n",
      "2026-01-09 16:15:13,417 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:13,419 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:13,419 - INFO - Processing document 0902.2588v2.pdf\n",
      "2026-01-09 16:15:14,889 - INFO - Finished converting document 0902.2588v2.pdf in 1.78 sec.\n",
      "2026-01-09 16:15:15,533 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:15,537 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:15,538 - INFO - Processing document 1702.00719v2.pdf\n",
      "2026-01-09 16:15:21,135 - INFO - Finished converting document 2103.10116v1.pdf in 11.00 sec.\n",
      "2026-01-09 16:15:21,349 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:21,356 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:21,357 - INFO - Processing document 2206.04592v1.pdf\n",
      "2026-01-09 16:15:25,551 - INFO - Finished converting document 1702.00719v2.pdf in 10.62 sec.\n",
      "2026-01-09 16:15:25,798 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:25,800 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:25,800 - INFO - Processing document 2310.06916v1.pdf\n",
      "2026-01-09 16:15:28,479 - INFO - Finished converting document 2310.06916v1.pdf in 2.80 sec.\n",
      "2026-01-09 16:15:28,648 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:28,651 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:28,651 - INFO - Processing document 1604.00500v2.pdf\n",
      "2026-01-09 16:15:30,393 - INFO - Finished converting document 2206.04592v1.pdf in 9.17 sec.\n",
      "2026-01-09 16:15:30,888 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:30,892 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:30,893 - INFO - Processing document 1910.07855v1.pdf\n",
      "2026-01-09 16:15:32,471 - INFO - Finished converting document 1910.07855v1.pdf in 1.99 sec.\n",
      "2026-01-09 16:15:32,699 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:32,710 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:32,710 - INFO - Processing document 2111.11680v2.pdf\n",
      "2026-01-09 16:15:35,938 - INFO - Finished converting document 1604.00500v2.pdf in 7.41 sec.\n",
      "2026-01-09 16:15:36,163 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:36,166 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:36,167 - INFO - Processing document 0507454v3.pdf\n",
      "2026-01-09 16:15:40,218 - INFO - Finished converting document 2111.11680v2.pdf in 7.71 sec.\n",
      "\u001b[33m[WARNING] 2026-01-09 16:15:40,667 [RapidOCR] main.py:125: The text detection result is empty\u001b[0m\n",
      "2026-01-09 16:15:40,668 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:15:40,744 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:40,747 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:40,748 - INFO - Processing document 2209.11046v2.pdf\n",
      "2026-01-09 16:15:42,274 - WARNING - RapidOCR returned empty result!\n",
      "2026-01-09 16:15:45,271 - INFO - Finished converting document 0507454v3.pdf in 9.25 sec.\n",
      "2026-01-09 16:15:45,691 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:45,694 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:45,695 - INFO - Processing document 1505.01973v3.pdf\n",
      "2026-01-09 16:15:53,695 - INFO - Finished converting document 2209.11046v2.pdf in 13.40 sec.\n",
      "2026-01-09 16:15:53,893 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2026-01-09 16:15:53,894 - INFO - Going to convert document batch...\n",
      "2026-01-09 16:15:53,895 - INFO - Processing document 1003.4397v2.pdf\n",
      "2026-01-09 16:15:57,891 - INFO - Finished converting document 1505.01973v3.pdf in 12.54 sec.\n",
      "2026-01-09 16:15:58,716 - INFO - Finished converting document 1003.4397v2.pdf in 4.92 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 1 reading: Sharpening and generalizations of Carlson's double...\n",
      "GPU 1 reading: The Sums of a Double Hypergeometric Series and of ...\n",
      "GPU 1 reading: Leveraging Intel SGX to Create a Nondisclosure Cry...\n",
      "GPU 1 reading: Subclasses of Normal Helly Circular-Arc Graphs...\n",
      "GPU 1 reading: Concise sharpening and generalizations of Shafer's...\n",
      "GPU 1 reading: Intel MPX Explained: An Empirical Study of Intel M...\n",
      "GPU 1 reading: Distributed Transfer Learning with 4th Gen Intel X...\n",
      "GPU 1 reading: Elzar: Triple Modular Redundancy using Intel Advan...\n",
      "GPU 1 reading: The Lensed Arc Production Efficiency of Galaxy Clu...\n",
      "GPU 1 reading: Algebraic structure of aromatic B-series...\n",
      "Synthesizing Cited Meta-Report on Intel Arc B-Series...\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://router.huggingface.co/groq/openai/v1/chat/completions (Request ID: Root=1-696129bf-2745d3df4d6dce1d3339f088;3122752f-13e4-4a8c-b9db-80217242db74)\n\nYou have reached the free monthly usage limit for groq. Subscribe to PRO to get 20x more included usage, or add pre-paid credits to your account.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:402\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/groq/openai/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mrun_research_mission\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIntel Arc B-Series\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m, in \u001b[0;36mrun_research_mission\u001b[0;34m(topic_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m llm \u001b[38;5;241m=\u001b[39m InferenceClient(api_key\u001b[38;5;241m=\u001b[39mHF_TOKEN)\n\u001b[1;32m     42\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a Senior Silicon Architect. Analyze the data into a 2000-word deep-dive on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMPORTANT: You must use in-text citations like [1] or [2] whenever you mention a fact, benchmark, or architecture detail. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase your citations on the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA FROM SOURCE [X]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m headers provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m report_response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHardware Raw Data:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfull_corpus_with_citations\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Combine the AI's report with our generated bibliography\u001b[39;00m\n\u001b[1;32m     58\u001b[0m final_report \u001b[38;5;241m=\u001b[39m report_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m+\u001b[39m bibliography\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:915\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    887\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload_model,\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    907\u001b[0m }\n\u001b[1;32m    908\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m    909\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    910\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    914\u001b[0m )\n\u001b[0;32m--> 915\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:275\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:475\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://router.huggingface.co/groq/openai/v1/chat/completions (Request ID: Root=1-696129bf-2745d3df4d6dce1d3339f088;3122752f-13e4-4a8c-b9db-80217242db74)\n\nYou have reached the free monthly usage limit for groq. Subscribe to PRO to get 20x more included usage, or add pre-paid credits to your account."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_research_mission(\"Intel Arc B-Series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61769e14-4a0d-4f59-8528-0fe7569f5fb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0bada-5b22-4898-9ff0-89e1da7af02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling arxiv requests huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fa66d-fb01-4138-a73f-d52bf4ae8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate>=0.26.0 transformers>=4.38.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5542e-c765-486d-8911-25d9bfd738e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f1e35-3f4d-4968-8f50-963fb3a3de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6db0c-785e-4afe-b895-6860fcd04d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling arxiv requests huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a8e0c-8a58-4e3d-b5c8-d1a867aa124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b33518-2183-40ea-b67e-6394adddc9c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.130.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.28.1)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-cloud-aiplatform)\n",
      "  Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (6.33.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.7.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.38.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.55.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.12.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (4.12.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.6.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.1)\n",
      "Downloading google_cloud_aiplatform-1.133.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "Installing collected packages: google-auth, google-cloud-aiplatform\n",
      "\u001b[2K  Attempting uninstall: google-auth\n",
      "\u001b[2K    Found existing installation: google-auth 2.43.0\n",
      "\u001b[2K    Uninstalling google-auth-2.43.0:\n",
      "\u001b[2K      Successfully uninstalled google-auth-2.43.0\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/2\u001b[0m [google-auth]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~uth'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/2\u001b[0m [google-auth]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~auth2'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: google-cloud-aiplatform\n",
      "\u001b[2K    Found existing installation: google-cloud-aiplatform 1.130.0oogle-auth]\n",
      "\u001b[2K    Uninstalling google-cloud-aiplatform-1.130.0:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-aiplatform-1.130.0‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/2\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [google-cloud-aiplatform]-cloud-aiplatform]\n",
      "\u001b[1A\u001b[2KSuccessfully installed google-auth-2.47.0 google-cloud-aiplatform-1.133.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ac8b66-92c6-4cfd-9815-c338a4282422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth in /opt/conda/lib/python3.10/site-packages (2.47.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.133.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth) (0.6.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.28.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (6.33.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.7.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.38.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.55.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.12.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.15.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (4.12.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Force-upgrade the auth and aiplatform libraries to be in sync\n",
    "!pip install --upgrade google-auth google-cloud-aiplatform --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac788767-c209-422c-9266-da8fbccf5d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
